{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Corpus Computer Readable; or What is OCR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<< Previous module: [Gathering a Corpus](02-GatheringACorpus.ipynb) <<**\n",
    "\n",
    "*30-45 minutes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>By the end of this module, you should be able to</strong>\n",
    "    <ul>\n",
    "        <li>define \"OCR\";</li>\n",
    "        <li>explain the importance of OCR for computer-aided reading and analysis;</li>\n",
    "        <li>identify different OCR tools and their affordances.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Computers Reading](#computers-reading)\n",
    "- [Why is OCR Important?](#ocr-important)\n",
    "- [Making Digitized Text Computer Readable](#making-readable)\n",
    "- [OCR Tools](#ocr-tools)\n",
    "- [Resources](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computers Reading <a class=\"anchor\" id=\"computers-reading\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember back to the last module when we discussed [corpus structures and formats](02-GatheringACorpus.ipynb#corpus-formats). We looked at this sample text from the *On The Books* corpus:\n",
    "\n",
    "[<img src=\"images/06-corpus-03.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of a volume of North Carolina laws shown in PDF format on the Internet Archive\" title=\"Screenshot of a volume of North Carolina laws shown in PDF format on the Internet Archive\" />](https://archive.org/details/lawsresolutionso1887nort/page/776/mode/2up)\n",
    "\n",
    "The text as it's shown to us in the screenshot above and in the Internet Archive is an *image*. It was created by archivists who used a scanner or camera to create a digital copy of the print (paper) version of this text. The printed volume is represented by 1 image per single-sided page. The archivists then created several different digital versions (file formats), added information (metada) about the volume, and uploaded all of these files to the Internet Archive to share with the world.\n",
    "\n",
    "While we humans see this file, know that it contains text, and possibly can read the text shown, the computer doesn't understand it that way. Here's a small amount of what the computer \"reads\":\n",
    "\n",
    "<img src=\"images/07-ocr-01.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of text stored in an image format from a page of North Carolina laws\" title=\"Screenshot of text stored in an image format from a page of North Carolina laws\" />\n",
    "\n",
    "While we might see this as the word `Blackwell's`, the computer understands the above as a series of squares, **pixels**, containing information about which color the pixel should be--*not* which character to display.  If we want the computer to be able to work this text *as* text, we need to convert the image above into this:\n",
    "\n",
    "`01000010 01101100 01100001 01100011 01101011 01110111 01100101 01101100 01101100 00100111 01110011`\n",
    "\n",
    "...which the computer will then display for human readers as `Blackwell's`. We can then use our computers to search for instances of this word, analyze its freqency, patterns in occurrence, collocation, and so on. We can also ask the computer to read this and any other words in the page aloud if we need to hear them instead of viewing them on a screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>If you want to learn more about how computers parse text, check out <a href=\"https://catalog.lib.unc.edu/catalog/UNCb10348476\" alt=\"link to Hermeneutica in UNC's catalog\">\"The Measured Words: How Computers Analyze Texts\"</a> in Rockwell & Sinclair's <em>Hermeneutica</em>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But how do we go from a computer-genrated image *of* text to *computer-readable text*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer lies in something called \"Optical Character Recognition,\" or \"OCR\" for short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    <p>OCR, <strong>\"Optical Character Recognition,\" is a computational process--algorithms!--that converts digital images of text into computer-readable text.</strong></p>\n",
    "    <p>More specifically:</p>\n",
    "    <blockquote>\"Optical character recognition (OCR) software is <strong>a type of artificial intelligence software designed to mimic the functions of the human eye and brain and discern which marks within an image represent letterforms or other markers of written language.</strong> OCR scans an image for semantically-meaningful material and transcribes what language it finds into text data. Typically OCR is used in situations where manual transcription would be too costly or time consuming—a subjective designation to be sure—such as when a large corpus has been scanned. Relative to manual transcription, OCR is a quick and affordable means for creating computable text data from a large collection of images.\" (<a href=\"https://ryancordell.org/research/why-ocr/\" alt=\"Why You (A Humanist) Should Care About Optical Character Recognition\">Cordell, \"Why OCR?\"</a>)</blockquote>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now a range of tools out there that do OCR--from free to very expensive; with varying degrees of computational expertise needed. We'll look at some of these [later in this module](#ocr-tools). But first:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is OCR important? <a class=\"anchor\" id=\"ocr-important\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Ryan Cordell [has written](https://ryancordell.org/research/why-ocr/), **\"even if you’ve never heard of OCR it may nonetheless be important or even essential to your research and teaching.\"**\n",
    "\n",
    "In the previous section, we noted that with computer-readable text we can search for words, analyze word frequencies and patterns, and ask computers to do things like read text aloud to us. The first and last of these capabilities can help us **access information**. Have you ever run a keyword search within a text on Google Books or [HathiTrust](https://babel.hathitrust.org/cgi/pt?id=uiug.30112001872933&view=1up&seq=79&q1=freedom)? Your ability to search a scanned text on these platforms has been made possible by OCR. Do you ever ask Adobe Acrobat, Siri, Cortana, Alexa, or Google Assistant to read a PDF aloud to you? That's also made possible by OCR.\n",
    "\n",
    "The radical potential of OCR for information access is that, along with digitization technologies, it can make important but previously physically inaccessible historical documents like the [\"Constitution of the American Society of Free Persons of Colour\"](https://omeka.coloredconventions.org/items/show/70) publicly available online and readable to people with many reading practices and abilities. OCR can bring history to laptops, phones, bluetooth speakers, classrooms, presentations, papers, communities, and more.\n",
    "\n",
    "OCR's ability to make information accessible, though, doesn't stop at helping to **access** (or consume) information. We can use OCR outputs (often with some human intervention) to create datasets for [**text analysis**](https://digitalpedagogy.hcommons.org/keyword/Text-Analysis). These analyses are conducted with the goal of exploring vast collections of information, and hopefully creating new understandings of those materials and their significance, using methods that humans can't conceivably complete in a reasonable amount of time without computational support. Here are a few examples of work that OCR has made possible:\n",
    "\n",
    "- [A computational analysis of the National Security Archive’s Kissinger Collections](https://blog.quantifyingkissinger.com/), containing tens of thousands of communications between Henry Kissinger and government officials between 1969-1977 (think Civil Rights, Vietnam, Watergate, Cold War...).\n",
    "- [Topic modeling of fugitive slave advertisements in Richmond, Virginia's, Civil War-era newspaper *The Dispatch*](https://dsl.richmond.edu/dispatch/topic/9).\n",
    "- The analysis of [hundreds of years' worth of women's writing](https://wwp.northeastern.edu/).\n",
    "\n",
    "In the [final module in this series](06-ExploratoryAnalysis.ipynb), we'll be exploring some of the methods used in text analysis with the *On The Books* Jim Crow corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Digitized Text Computer Readable <a class=\"anchor\" id=\"making-readable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>There are <strong>multiple possible ways</strong> to approach converting image files <em>showing</em> text that humans can read to text files <em>containing</em> computer readable text.</p>\n",
    "    <p>Some questions to consider when preparing to perform OCR:</p>\n",
    "   <ol>\n",
    "       <li>How much text do I need to convert?</li>\n",
    "       <li>Is the text born-digital or digitized from paper or another analog physical medium?</li>\n",
    "       <li>Is the text written by hand or printed using a press?</li>\n",
    "       <li>How is the text formatted on the page?</li>\n",
    "       <li>Is the digitized text showing signs of damage, such as fading, spills, smears, or paper disintigration or tearing?</li>\n",
    "       <li>Is the text using a historical script such as <a href=\"https://en.wikipedia.org/wiki/Carolingian_minuscule\" alt=\"Wikipedia page describing Carolingian miniscule\">Carolingian miniscule</a>?</li>\n",
    "       <li>Is the text in a human language that computers can \"read\"?</li>\n",
    "    </ol>\n",
    "    <p>Some of these questions may not be relevant to you, but they are worth being aware of. We'll go through each briefly below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with this question because if you have only a few pages, there may be merit in typing them out by hand in a text editor, and perhaps working with a team to do so. If you have hundreds of thousands of pages, though, it may take far longer than you have time, even working with a team, to manually transcribe every page you need to complete a project. That may mean that you'll want to start with an automated transcription (OCR) process and then work to correct what the computer outputs. *There are caveats to this method--read on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the text born-digital or digitized from paper or another analog physical medium?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Born-digital texts in PDF and image formats can be easier for a computer to \"read\" than are scanned documents,** even if the scanners use the highest resolution equipment. This is particularly true of older printed texts for reasons that we'll learn more about below.\n",
    "\n",
    "**An exception to this is if a born-digital text is stored in an image or other non-text-editable format that is uncommon, proprietary, or outdated.** Then computers may have a hard time accessing the file in order to parse the text contained. (So always save documents in an interoperable--can be opened by different software programs--file format either as [editable text](https://www.archives.gov/records-mgmt/policy/transfer-guidance-tables.html#textualdata) or as [non-editable image or archival document--PDF--formats](https://www.archives.gov/records-mgmt/policy/transfer-guidance-tables.html#scannedtext).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the text written by hand or printed using a press?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR technologies were **initially developed to deal only with digitized texts created using a [printing press](https://en.wikipedia.org/wiki/Printing_press)**. This was because printing presses offer a certain amount of consistency in typeface, font, and layout that programmers could use to create rules for computers to follow (algorithms!). Meanwhile, handwriting is, by and large, more individualistic and inconsistent. Most programs for OCR still focus only on printed texts, but **there are a growing number of projects and toolkits now available for what's called variously [\"digital paleography\"](https://academic.oup.com/dsh/article/32/suppl_2/ii89/4259068), [\"handwriting recognition\" (HWR)](https://en.wikipedia.org/wiki/Handwriting_recognition), and [\"handwritten text recognition\" (HTR)](https://en.wikipedia.org/wiki/Handwriting_recognition).**\n",
    "\n",
    "As an example, **let's compare excerpts from Toni Morrison's *Beloved*.** The first image below is a page from an early draft, written in Morrison's own hand on a legal pad. The second image is a segment from a digitized print version. These are not the same passages, but they are noticably different in how we read them: Try reading each. What's different about the experience--think about order of reading, ease of reading, and any other differences that come to mind:\n",
    "\n",
    "<img src=\"images/07-ocr-03.jpeg\" width=\"p0%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"A page from Toni Morrison's early draft of Beloved. Courtesy of Princeton University Library\" title=\"A page from Toni Morrison's early draft of Beloved. Courtesy of Princeton University Library\" />\n",
    "\n",
    "An early draft of Toni Morrison's *Beloved*. Image credit: [Princeton University Library](https://blogs.princeton.edu/manuscripts/2016/06/07/toni-morrison-papers-open-for-research/)\n",
    "\n",
    "<img src=\"images/07-ocr-02.jpeg\" width=\"90%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of a page in Toni Morrison's Beloved. Preview hosted on Google Books.\" title=\"Screenshot of a page in Toni Morrison's Beloved. Preview hosted on Google Books.\" />\n",
    "\n",
    "Screenshot from a digitized version of the published *Beloved*, available in [Google Books](https://www.google.com/books/edition/Beloved/sfmp6gjZGP8C?hl=en&gbpv=1&dq=toni+morrison+beloved&printsec=frontcover).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is the text formatted on the page?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look at the texts above again: How are they formatted similarly or differently?** While both use a left-to-right writing system, the printed version appears in a single column that is evenly spaced both horizontally and vertically. The manuscript text appears on lined paper in a single column, but it includes a number of corrections written between lines or even in different directions (vertically) on the page. You might have tilted your head to read some of that text--if you had been holding the paper in your hands, you might have turned the paper 90 degrees. But computers don't necessarily know to do that (yet). They need a predictable pattern to follow, which the printed text provides.\n",
    "\n",
    "That said, not all historical printings are as regular as this *Beloved* excerpt. Let's take a look at one more example from *On The Books*:\n",
    "\n",
    "<img src=\"images/07-ocr-04.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot from the 1887 North Carolina session laws digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot from the 1887 North Carolina session laws digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "Like the printed *Beloved* example, this selection from the [1887 North Carolina session laws](https://archive.org/details/lawsresolutionso1887nort/page/776/mode/2up) was created using a printing press and with mostly even vertical spacing between lines that run left to right. However, in addition to the changing typeface, there is in addition to the main column of text a much smaller column of annotations--[\"marginalia\"](https://en.wikipedia.org/wiki/Marginalia)--created to aid readers who would have been looking for quick topical references rather than reading a volume from start to finish. These created a problem for the *On The Books* team because the computer read them as being part of the main text. What resulted (with other OCR errors removed) would have looked like:\n",
    "\n",
    "`SECTION 1. The Julian S. Carr, of Durham, North Carolina, Mar- Body politic. cellus E. McDowell, Samuel H. Austin, Jr., and John A. McDowell,`\n",
    "\n",
    "What's the problem here? The marginalia, `Body politic`, have been interspersed with the text as the computer \"reads\" all the way across the page. The line should read:\n",
    "\n",
    "`SECTION 1. The Julian S. Carr, of Durham, North Carolina, Mar-cellus E. McDowell, Samuel H. Austin, Jr., and John A. McDowell,`\n",
    "\n",
    "The computer doesn't realize that it's creating errors, and if the annotations are not in any way mispelled, the *On The Books* team might have a hard time finding and removing all of these insertions. The insertions might then have also caused major difficulties in future computational analyses.\n",
    "\n",
    "Because marginalia would have caused such havoc in their dataset, the *On The Books* team decided to remove the marginalia as part of preparing for OCR. We don't cover how to do this in these modules, but you can [find the documentation in the team's Github](https://github.com/UNC-Libraries-data/OnTheBooks/tree/master/examples/marginalia_determination).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the digitized text showing signs of damage, such as fading, spills, smears, or paper disintigration or tearing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the use of state of the art scanning equipment ([for example](https://www.digitalnc.org/about/what-we-use-to-digitize-materials/)), annotations on or damage to analog physical media can interfere with OCR. Here are some examples.\n",
    "\n",
    "**Someone writing on a printed text.** These check marks might be read as \"l\" or \"V\" by the computer:\n",
    "\n",
    "<img src=\"images/07-ocr-05.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of check marks written in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of check marks written in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`not be worked on said railroad in the counties of New l Hanover or Pender.`\n",
    "\n",
    "The **printed text has faded** so that individual characters are broken up, and the ink is harder to read. (Historic newpapers are notorious for this. [Here's an example](https://chroniclingamerica.loc.gov/lccn/sn85042104/1897-01-14/ed-1/seq-6/#date1=1890&index=2&rows=20&words=asylum+ASYLUM+Asylum&searchType=basic&sequence=0&state=North+Carolina&date2=1910&proxtext=asylum&y=0&x=0&dateFilterType=yearRange&page=1).):\n",
    "\n",
    "<img src=\"images/07-ocr-06.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of faded text printed in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of faded text printed in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`three hundred dollars' t\\\"Orth of property and the same arnouut`\n",
    "\n",
    "A **smudge, spot, or spill has appeared on the page**, causing the computer to misinterpret a character or eroneously add characters:\n",
    "\n",
    "<img src=\"images/07-ocr-06.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of spot on text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of spot on text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "\n",
    "`a S€1'.)arate fund,`\n",
    "\n",
    "There is also one additional possibility that can be a result of close binding, or the human doing the scanning avoiding the possibility of breaking tight or damaged binding: that is, **text that is rotated slightly** on the digitized page so that it appears at a slight angle. We'll touch on how to address this in [the next module](04-HowToOCR.ipynb).\n",
    "\n",
    "<img src=\"images/07-ocr-08.jpeg\" width=\"70%\" style=\"padding-top:20px; box-shadow: 25px 25px 20px -30px rgba(0, 0, 0);\" alt=\"Screenshot of tilted text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" title=\"Screenshot of tilted text in 1887 North Carolina sessions law digitized by UNC Libraries and shared via the Internet Archive.\" />\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the text using a historical script such as [Carolingian miniscule](https://en.wikipedia.org/wiki/Carolingian_minuscule)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applies mainly to students and scholars working with **historical texts printed or written in scripts that are not commonly legible to humans (or computers) today**. These could be anything from medieval scripts like Carolingian miniscule to neogothic scripts used in [twentieth-century German-American newspapers](https://chroniclingamerica.loc.gov/lccn/sn84027107/1915-07-01/ed-1/seq-1/) to the many, many historic non-Western scripts. These are areas where research is in progress, but you might find this [Manuscript OCR](https://manuscriptocr.org/) tool of interest as well as this [essay on the challenges medievalists continue to face when using OCR technologies](http://digitalhumanities.org/dhq/vol/13/1/000412/000412.html). When choosing an OCR tool, this is one of the capabilities you'll want to check for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the text in a human language that computers can \"read\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the historic script issue, for scholars and students working with or studying **less common, perhaps endangered, and especially non-Western languages**, you'll want to see if an OCR tool supports your particular language. Tesseract, a version of which we'll use later in these modules, offers [a list of the languages and scripts it supports](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html). Tesseract supports 125 languages and dialects--likely those most commonly spoken, based on shared [writing systems](https://en.wikipedia.org/wiki/Writing_system), and/or those that researchers may have invested time in training Tesseract to \"read\" for some specific reason. This is just a fraction of the languages and scripts in the world, though. \n",
    "\n",
    "Unfortunately, if you're working with Indigenous writing systems such as [Canadian Aboriginal Syllabics](https://en.wikipedia.org/wiki/Canadian_Aboriginal_syllabics), you still may need to seek out additional support from computer scientists for developing OCR technologies to \"read\" these languages. This lack of support for many endangered languages is just one example of bias found in the broader technology industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>Read more about the current state of OCR for historical and humanities-oriented computation in <a href=\"http://hdl.handle.net/2047/D20297452\" alt=\"A Research Agenda for Historical and Multilingual Optical Character Recognition \">this report from experts at Northeastern University</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answering the questions above are helpful not only for understanding the affordances and limitations of OCR, but also for assessing which OCR method(s) are most appropriate for your project.** We'll see these come up in the [next module](04-HowToOCR.ipynb), which will walk through one method for performing OCR. First, though, let's take a look at some of the different tools available for OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Tools<a class=\"anchor\" id=\"ocr-tools\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have [Adobe Acrobat](https://acrobat.adobe.com/us/en/) on your computer, then you have probably already been using software that contains OCR functionality. Acrobat's OCR is designed to help users [edit scanned PDFs or PDFs created by others](https://helpx.adobe.com/acrobat/using/edit-scanned-pdfs.html). It can also be used to export editable text versions (e.g. Microsoft Word documents), or to ask the computer to read aloud the text contained in the PDF. However, *at scale* and working with *older printed documents, perhaps with irregular printing patterns*, Acrobat may not be your best bet. Especially if you don't have a *license* for it. (Note: UNC staff & faculty can access Adobe Acrobat Pro, which has these functionalities. UNC students have access only to Acrobat Reader for viewing PDFs. Check the [software list here](https://software.sites.unc.edu/shareware/#a).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <p>As with the questions we reviewed above, selecting an OCR tool is best done when considering:</p>\n",
    "    <ol>\n",
    "        <li>Is the tool <strong>proprietary or open source</strong>?</li>\n",
    "        <li>Does it include a <strong>GUI (graphical user interface)</strong>, such as in Adobe Acrobat, where users can click a button to produce OCR'ed text? Or is it run in a <strong>script</strong>?</li>\n",
    "        <li>What kinds of <strong>file types</strong> can it process?</li>\n",
    "        <li>Which <strong>languages</strong> can it handle?</li>\n",
    "        <li>Which [human] <strong>scripts</strong> can it read?</li>\n",
    "        <li>Does it come with any kind of <strong>preprocessing</strong> features?</li>\n",
    "    </ol>\n",
    "    <p>There may be other questions you'll need to add to this list, but it will get you started. Likewise, you may wish to reorder these questions based on your project's priorities. We'll work through each briefly below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the tool proprietary or open source?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proprietary, meaning do you need to purchase a license? Knowing the resources you have or need to start your OCR project is key to how you make your decision. You may wish to work with a program such as [ABBYY FineReader](https://pdf.abbyy.com/pricing/), which includes a number of graphical features for preprocessing (read on) that you'd like to use. But you'll need to be prepared to pay $200-300 for it. If you don't have those funds, you may wish to work with a free tool. \n",
    "\n",
    "Although *free* software is not necessarily the same as *open source* software, [open source](https://en.wikipedia.org/wiki/Open-source_model) software is free. **Open source, in the software world, refers to software whose creators have made the underlying code available for others to edit and build upon.** You may opt to choose an open source OCR tool as a form of [algorithmic resistance](01-AlgorithmsOfResistance-WhatIsAnAlgorithm.ipynb#resistance), and/or you may choose open source so that you have more access to the codebase, and therefore better understanding of the computation that goes into performing OCR on your corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it include a GUI (graphical user interface), or is it run in a script?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working on a project alone with no coding experience, you may be thinking that a GUI that provides the ease of clicking a button is the best way to go--and it may be if you have very limited time. On the other hand, you may wish to learn some coding. If so, learning how to run OCR with Python is a great opportunity. Even if you're collaborating with a programmer who will write most of your OCR code, you may want to learn some of the concepts and basic steps behind the OCR to ensure you have a good understanding of this project phase and to aid communications with your collaborator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What kinds of file types can it process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the OCR tool work only with PDFs, or can it also read image files? Which file type(s) are you working with? This may seem a small point, but if you have image files, and you purchase a license for OCR software that works only with PDFs, you may be a bit surprised. There are tools out there that can help you convert images to PDFs, but you may risk degrading the scanned text with these conversations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which languages can it handle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with texts that are not in English, it's a good idea to check--remember our discussion above about Canadian Aboriginal Syllabics? At this point, most OCR tools work with multiple languages, and some work with many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which [human] scripts can it read?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, remember our discussion of Carolingian miniscule? If you're working with a language written in a script no longer commonly in use, you may need to seek out some specific tools to assist you. Even if you're working with [late-nineteenth- and early-twentieth-century American non-English newspapers](https://chroniclingamerica.loc.gov/lccn/sn93060356/1917-01-18/ed-1/seq-1/#date1=1880&index=11&date2=1917&searchType=advanced&language=&sequence=0&words=son+sonille&proxdistance=5&state=Missouri&rows=20&ortext=son&proxtext=&phrasetext=&andtext=&dateFilterType=yearRange&page=1), you may need to find out which tools handle specific scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it come with any kind of preprocessing features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember all of the [considerations for making a text computer readable](#making-readable)? **Preprocessing is a set of steps that we can use to try to minimize issues such as a skewed page, faded text, or smudges on a page *before* performing OCR.** Some OCR tools offer some preprocessing tools. Other's don't. Even if a tool can run preprocessing, though, you may find you have a specific need that must be met with another tool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these questions in mind, let's take a look at a few different tools:\n",
    "\n",
    "#### [Pytesseract](https://pypi.org/project/pytesseract/)\n",
    "Pytesseract (or Python-tesseract) is a powerful OCR tool made for the programming language Python using Google's Tesseract OCR Engine. It can work with many file formats and (human) languages, and, like [Tesseract](https://github.com/tesseract-ocr/tesseract), is open source. Since Pytesseract is used in a larger programming ecosystem, it can be combined with a variety of other Python packages to perform many different tasks. Programmers have taken advantage of this and created [a number of tools based on Tesseract](https://tesseract-ocr.github.io/tessdoc/User-Projects-%E2%80%93-3rdParty) (some with GUIs). Furthermore, Python is both highly used and a popular computer language for beginning programmers, making it possible for users to move quickly from the basics of Python into working with Pytesseract.\n",
    "\n",
    "#### [ABBYY Fine Reader](https://pdf.abbyy.com/)\n",
    "Perhaps at the opposite end of the OCR spectrum from Pytesseract, ABBYY is another powerful OCR tool. It has a GUI (graphical user interface) in which users can make adjustments (preprocessing), and it also has an SDK (software developer toolkit) that programmers can use to run ABBYY tools in their own programs. ABBYY even has a cloud service. Like Tesseract, ABBYY supports many languages and a number of file formats. ABBYY is, however, proprietary--you'll need to be prepared to pay a minimum of $200 if your institution does not provide a license.\n",
    "\n",
    "#### [Amazon Textract](https://aws.amazon.com/textract/resources/?blog-posts-cards.sort-by=item.additionalFields.createdDate&blog-posts-cards.sort-order=desc)\n",
    "Like Pytesseract, this tool from Amazon runs in Python. Like ABBYY Fine Reader, it's proprietary code, which means we don't know what's happening in Textract itself when we use it--it's a black box. There is a free tier to get started if you're working with fewer than 1,000 pages, and you can run your Textract code in Amazon's cloud environment. The cost to use it, if you are planning to learn a little programming or are working with a programmer, is significantly lower than the cost of an ABBYY license.\n",
    "\n",
    "#### [Google Cloud Vision](https://cloud.google.com/vision/docs)\n",
    "A competitor of Amazon's, Google's Cloud Vision API (application programming interface) is likewise proprietary after a certain number of uses, requires programming knowledge, and can be used in the cloud. This same tool can be used to perform computer vision tasks such as facial recognition. Because we don't know what's happening in Cloud Vision's code when we use it, we might not be able to explain unexpected results--it's another [black box](01-AlgorithmsOfResistance-WhatIsAnAlgorithm.ipynb#algorithms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <p>You'll note that we haven't included Adobe Acrobat on this list. While Adobe does provide OCR functionality in Acrobat, we don't recommend trying to use Adobe to process a text corpus unless your corpus is very small and very legible. There are certainly more tools available. Here's a <a href=\"https://en.wikipedia.org/wiki/Comparison_of_optical_character_recognition_software\" alt=\"comparative list maintained on Wikipedia\">comparative list maintained on Wikipedia</a>.</p>\n",
    "    <p>Now that we have a basic understanding of OCR, let's give it a try in the <a href=\"04-HowToOCR.ipynb\" target=\"blank\">next module</a>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources <a class=\"anchor\" id=\"resources\"></a>\n",
    "\n",
    "- Cordell, R. 2017. \"Q i-jtb the Raven\": Taking Dirty OCR Seriously.\" *Book History*, 20, 188-225. http://dx.doi.org.libproxy.lib.unc.edu/10.1353/bh.2017.0006, https://ryancordell.org/research/qijtb-the-raven/\n",
    "- Cordell, Ryan. 2019. \"Why You (A Humanist) Should Care About Optical Character Recognition.\" *Ryan Cordell.* https://ryancordell.org/research/why-ocr/\n",
    "- Houston, Natalie M. \"Text Analysis\" in *Digital Pedagogy in the Humanities.* https://digitalpedagogy.hcommons.org/keyword/Text-Analysis\n",
    "- Milligan, I. 2013. Illusionary Order: Online Databases, Optical Character Recognition, and Canadian History, 1997–2010. *The Canadian Historical Review* 94(4), 540-569. https://www.muse.jhu.edu/article/527016.\n",
    "- Rockwell, Geoffrey, and Stéfan Sinclair. 2016. *Hermeneutica: Computer Assisted Interpretation in the Humanities.* https://catalog.lib.unc.edu/catalog/UNCb10348476 \n",
    "- Smith, David, and Ryan Cordell. 2018. \"A Research Agenda for Historical and Multilingual Optical Character Recognition. http://hdl.handle.net/2047/D20297452\n",
    "- Smith, Ray. 2007. \"An Overview of the Tesseract OCR Engine.\" https://tesseract-ocr.github.io/docs/tesseracticdar2007.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**>> Next module: [How to OCR](04-HowToOCR.ipynb) >>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This module is licensed under the [GNU General Public License v3.0](https://github.com/UNC-Libraries-data/OnTheBooks/blob/master/LICENSE). Individual images and data files associated with this module may be subject to a different license. If so, we indicate this in the module text.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
