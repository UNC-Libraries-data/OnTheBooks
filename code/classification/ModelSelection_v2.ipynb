{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac23276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Text Libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#Model Tuning Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "#Evaluation Libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "#Supress \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc3507",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We used a 80-20 train-test split, retaining 20% of the dataset to estimate model performance and using the remaining 80% to select a model. Several candidate models were compared using grid-search cross validation.  This process suggested the use of an XGBoost model.  Using this model, we refined our selected hyperparameters using the hyperopt package to \n",
    "\n",
    "## Data Ingest and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ef5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('training_set_v2.csv')\n",
    "#Drop Extrinsic Laws\n",
    "dataframe['year'] = dataframe['id'].astype(str).str[:4].astype('int64')\n",
    "dataframe = pd.get_dummies(dataframe, columns=['type'])\n",
    "categorical_cols =  dataframe.select_dtypes(include=['uint8'])\n",
    "features = dataframe.loc[:,['year','section_text']].copy()\n",
    "features = pd.concat([features, categorical_cols], axis=1)\n",
    "target = dataframe['jim_crow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44547fc6",
   "metadata": {},
   "source": [
    "20% of the data is set aside for assessment and the remaining 80% is used to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40123f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a126b19",
   "metadata": {},
   "source": [
    "## Preprocessing and Analysis Setup\n",
    "\n",
    "The analysis is packaged into a scikit-learn Pipeline to ensure that all steps can be easily applied within cross-validation folds.  Some feautres (e.g. tf-idf) could allow data from validation (or even the test set) to leak through if performed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea5404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')\n",
    "# regular expression to identify non-ascii characters\n",
    "non_ascii_regex = r'[^\\x00-\\x7F]+'\n",
    "def tokenize(text):     \n",
    "    text = re.sub(non_ascii_regex, ' ', text)  \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopword]\n",
    "    return clean_tokens\n",
    "\n",
    "class LengthExtractor(BaseEstimator, TransformerMixin):   \n",
    "    def compute_length(self, text):\n",
    "        sentence_list = word_tokenize(text)\n",
    "        return len(sentence_list) \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_length = pd.Series(X).apply(self.compute_length)\n",
    "        return pd.DataFrame(X_length)\n",
    "\n",
    "\n",
    "class SelectColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "    def transform(self, X, **transform_params):\n",
    "        out = X[self.columns].copy()\n",
    "        return out\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65368b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
    "                      min_df = 2, max_df = 1000)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "            ])),\n",
    "            ('text_len', Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ])),\n",
    "            ('metadata', SelectColumnsTransformer())\n",
    "        ])),\n",
    "        # set default estimator RandomForestClassifier \n",
    "        ('dlf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698380a",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Candidate models' performance was compared using grid search cross validation, measured using F1 scores.  Parameters passed to the param_grid below change the behavior of the underlying estimators and the preprocessing defined in the Pipeline above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27836aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {#####Random Forest#####\n",
    "    'features__text_pipeline__vect__min_df': [2, 10],\n",
    "    'features__text_pipeline__vect__max_df': [0.5,0.9],\n",
    "    'features__text_pipeline__vect__lowercase': [True,False],\n",
    "    'features__text_pipeline__vect__ngram_range': [(1,1),(1,2)],\n",
    "    'features__text_pipeline__tfidf': [TfidfTransformer(), 'passthrough'],\n",
    "    'features__text_len': [Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ]), 'passthrough'],\n",
    "    'features__metadata__columns': [[],['type_private laws', 'type_public laws',\n",
    "                                        'type_public local laws','type_session laws','year']],\n",
    "    'dlf' : [RandomForestClassifier()],\n",
    "    'dlf__n_estimators' : [50, 100, 500, 1000],\n",
    "    'dlf__max_depth' : [100, 200, 300],\n",
    "    'dlf__class_weight' : [None, \"balanced\"]\n",
    "    },\n",
    "    {#####Multinomial Naive Bayes#####\n",
    "    'features__text_pipeline__vect__min_df': [2,10],\n",
    "    'features__text_pipeline__vect__max_df': [0.5,0.9],\n",
    "    'features__text_pipeline__vect__lowercase': [True,False],\n",
    "    'features__text_pipeline__vect__ngram_range': [(1,1),(1,2)],\n",
    "    'features__text_pipeline__tfidf': [TfidfTransformer(), 'passthrough'],\n",
    "    'features__text_len': [Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ]), 'passthrough'],\n",
    "    'features__metadata__columns': [[],['type_private laws', 'type_public laws',\n",
    "                                        'type_public local laws','type_session laws','year']],\n",
    "    'dlf' : [MultinomialNB()],\n",
    "    'dlf__alpha':  [1, 0.01, 0.0001]\n",
    "    },\n",
    "    {#####Stochastic Gradient Descent Classifier (including SVM)#####\n",
    "    'features__text_pipeline__vect__min_df': [2,10],\n",
    "    'features__text_pipeline__vect__max_df': [0.5,0.9],\n",
    "    'features__text_pipeline__vect__lowercase': [True,False],\n",
    "    'features__text_pipeline__vect__ngram_range': [(1,1),(1,2)],\n",
    "    'features__text_pipeline__tfidf': [TfidfTransformer(), 'passthrough'],\n",
    "    'features__text_len': [Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ]), 'passthrough'],\n",
    "    'features__metadata__columns': [[],['type_private laws', 'type_public laws',\n",
    "                                        'type_public local laws','type_session laws','year']],\n",
    "    'dlf' : [SGDClassifier()],\n",
    "    'dlf__loss':  [\"hinge\", \"modified_huber\",\"log\"],\n",
    "    'dlf__penalty': ['l2','elasticnet'],\n",
    "    'dlf__learning_rate': ['optimal'],\n",
    "    'dlf__alpha':  [1, 0.01, 0.0001]\n",
    "    },\n",
    "    {#####XGBoost#####\n",
    "    'features__text_pipeline__vect__min_df': [5,10],\n",
    "    'features__text_pipeline__vect__max_df': [0.7,0.9],\n",
    "    'features__text_pipeline__vect__lowercase': [True],\n",
    "    'features__text_pipeline__vect__ngram_range': [(1,1),(1,2)],\n",
    "    'features__text_pipeline__tfidf': ['passthrough'],\n",
    "    'features__text_len': [Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ]), 'passthrough'],\n",
    "    'features__metadata__columns': [['type_private laws', 'type_public laws',\n",
    "                                        'type_public local laws','type_session laws','year']],\n",
    "    'dlf' : [XGBClassifier()],\n",
    "    'dlf__learning_rate': [0.2, 0.3, 0.4],\n",
    "    'dlf__max_depth': [9, 12, 15],\n",
    "    'dlf__min_child_weight': [1, 3],\n",
    "    'dlf__gamma': [0.5, 1, 2],\n",
    "    'dlf__colsample_bytree' : [0.5, 0.6],\n",
    "    'dlf__scale_pos_weight' : [1,3],\n",
    "    'dlf__tree_method' : [\"hist\"]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f2ce6",
   "metadata": {},
   "source": [
    "The following loop summarizes the best performance by each model considered.  This search is time-intensive, so is disabled here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f588e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_dict = dict()\n",
    "# for params in param_grid:\n",
    "#     estimator = str(params[\"dlf\"][0]).replace(\"()\",\"\")\n",
    "#     fit_dict[estimator] = GridSearchCV(pipeline, param_grid=params, n_jobs = 32, cv=5, scoring='f1', verbose=1)\n",
    "#     _ = fit_dict[estimator].fit(X_train, y_train)\n",
    "#     print(estimator + \" COMPLETE ########################\")\n",
    "#     print(\"Best Score: \" + str(round(fit_dict[estimator].best_score_,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419fa21",
   "metadata": {},
   "source": [
    "The best fitting model was XGBoost (F1 Score: 0.9588).  We further refined this model using HyperOpt to better search the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9206c",
   "metadata": {},
   "source": [
    "## Bayesian Hyperparameter search with HyperOpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "661bfec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            # Extract features\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
    "                      min_df = 2, max_df = 0.8)),\n",
    "                ('tfidf', 'passthrough'),\n",
    "            ])),\n",
    "            ('text_len', Pipeline([\n",
    "                ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "                ('length', LengthExtractor())\n",
    "            ])),\n",
    "            ('metadata', SelectColumnsTransformer(['type_private laws', 'type_public laws',\n",
    "                                        'type_public local laws','type_session laws','year']))\n",
    "        ])),\n",
    "        ('dlf',XGBClassifier(tree_method=\"hist\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774ee6c7",
   "metadata": {},
   "source": [
    "Using the same pipeline as the previous process, we'll set up an objective function and define the parameter space we want to search within.  Again, we use the F1 score as our performance measure.  The example below runs a few trials.  The project used 1000 evals instead of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b58223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.9377 params {'dlf__colsample_bytree': 0.6228792662262748, 'dlf__gamma': 0.589206708162038, 'dlf__learning_rate': 0.8216976728629352, 'dlf__max_depth': 3, 'dlf__min_child_weight': 3, 'dlf__scale_pos_weight': 4, 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
      "                ('length', LengthExtractor())]), 'features__text_pipeline__vect__lowercase': True, 'features__text_pipeline__vect__max_df': 0.7516040448161234, 'features__text_pipeline__vect__min_df': 4, 'features__text_pipeline__vect__ngram_range': (1, 3)}\n",
      "F1 0.9328 params {'dlf__colsample_bytree': 0.9498850608152181, 'dlf__gamma': 0.12603934587749754, 'dlf__learning_rate': 0.7645360138092586, 'dlf__max_depth': 9, 'dlf__min_child_weight': 1, 'dlf__scale_pos_weight': 2, 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
      "                ('length', LengthExtractor())]), 'features__text_pipeline__vect__lowercase': False, 'features__text_pipeline__vect__max_df': 0.7352300368371185, 'features__text_pipeline__vect__min_df': 11, 'features__text_pipeline__vect__ngram_range': (1, 2)}\n",
      "F1 0.9481 params {'dlf__colsample_bytree': 0.3059776834203577, 'dlf__gamma': 1.7694174809957808, 'dlf__learning_rate': 0.24100630890479885, 'dlf__max_depth': 4, 'dlf__min_child_weight': 3, 'dlf__scale_pos_weight': 7, 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
      "                ('length', LengthExtractor())]), 'features__text_pipeline__vect__lowercase': True, 'features__text_pipeline__vect__max_df': 0.6041840045961325, 'features__text_pipeline__vect__min_df': 6, 'features__text_pipeline__vect__ngram_range': (1, 3)}\n",
      "F1 0.9525 params {'dlf__colsample_bytree': 0.6806352025275062, 'dlf__gamma': 1.4653103872599336, 'dlf__learning_rate': 0.1338333089876192, 'dlf__max_depth': 6, 'dlf__min_child_weight': 2, 'dlf__scale_pos_weight': 2, 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
      "                ('length', LengthExtractor())]), 'features__text_pipeline__vect__lowercase': True, 'features__text_pipeline__vect__max_df': 0.6663072734163493, 'features__text_pipeline__vect__min_df': 4, 'features__text_pipeline__vect__ngram_range': (1, 2)}\n",
      "F1 0.9369 params {'dlf__colsample_bytree': 0.36090203237009166, 'dlf__gamma': 0.7498581430383442, 'dlf__learning_rate': 0.1976279143114002, 'dlf__max_depth': 9, 'dlf__min_child_weight': 2, 'dlf__scale_pos_weight': 2, 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
      "                ('length', LengthExtractor())]), 'features__text_pipeline__vect__lowercase': False, 'features__text_pipeline__vect__max_df': 0.6570007340533367, 'features__text_pipeline__vect__min_df': 12, 'features__text_pipeline__vect__ngram_range': (1, 3)}\n",
      "100%|█████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.75s/trial, best loss: 0.04753930516886129]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, space_eval, Trials\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def objective(params):\n",
    "    params['features__text_pipeline__vect__min_df'] = int(params['features__text_pipeline__vect__min_df'])\n",
    "    params['dlf__max_depth'] = int(params['dlf__max_depth'])\n",
    "    params['dlf__min_child_weight'] = int(params['dlf__min_child_weight'])\n",
    "    params['dlf__scale_pos_weight'] = int(params['dlf__scale_pos_weight'])\n",
    "    pipeline.set_params(**params)\n",
    "    \n",
    "    score = 1-cross_val_score(pipeline, X_train, y_train, scoring=\"f1\", n_jobs=-1).mean()\n",
    "    print(\"F1 {:.4f} params {}\".format((1-score), params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'features__text_pipeline__vect__min_df': hp.quniform ('features__text_pipeline__vect__min_df',2,20,1),\n",
    "    'features__text_pipeline__vect__lowercase': hp.choice('features__text_pipeline__vect__lowercase',[True,False]),\n",
    "    'features__text_pipeline__vect__ngram_range': hp.choice('features__text_pipeline__vect__ngram_range',[(1,1),(1,2),(1,3),(1,4)]),\n",
    "    'features__text_pipeline__vect__max_df': hp.uniform('features__text_pipeline__vect__max_df',0.6,0.8),\n",
    "    'features__text_len':hp.choice('features__text_len',[Pipeline([\n",
    "            ('get_text', SelectColumnsTransformer(\"section_text\")),\n",
    "            ('length', LengthExtractor())\n",
    "        ])]),\n",
    "    'dlf__max_depth': hp.quniform('dlf__max_depth', 2, 10, 1),\n",
    "    'dlf__min_child_weight': hp.quniform('dlf__min_child_weight', 1, 5, 1),\n",
    "    'dlf__colsample_bytree': hp.uniform('dlf__colsample_bytree', 0.3, 1.0),\n",
    "    'dlf__learning_rate': hp.uniform('dlf__learning_rate', 0.05, 1),\n",
    "    'dlf__scale_pos_weight': hp.quniform('dlf__scale_pos_weight',1,8,1),\n",
    "    'dlf__gamma': hp.uniform('dlf__gamma',0,2)\n",
    "    \n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=5, #actual fit was run with 1000 evals\n",
    "           trials=trials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892cb56",
   "metadata": {},
   "source": [
    "The example search above selected the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8544eb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dlf__colsample_bytree': 0.6806352025275062,\n",
       " 'dlf__gamma': 1.4653103872599336,\n",
       " 'dlf__learning_rate': 0.1338333089876192,\n",
       " 'dlf__max_depth': 6.0,\n",
       " 'dlf__min_child_weight': 2.0,\n",
       " 'dlf__scale_pos_weight': 2.0,\n",
       " 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
       "                 ('length', LengthExtractor())]),\n",
       " 'features__text_pipeline__vect__lowercase': True,\n",
       " 'features__text_pipeline__vect__max_df': 0.6663072734163493,\n",
       " 'features__text_pipeline__vect__min_df': 4.0,\n",
       " 'features__text_pipeline__vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_eval(space, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25510240",
   "metadata": {},
   "source": [
    "The final results were based on the following parameters, selected in a larger search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad37d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('text_pipeline',\n",
       "                                                 Pipeline(steps=[('get_text',\n",
       "                                                                  SelectColumnsTransformer(columns='section_text')),\n",
       "                                                                 ('vect',\n",
       "                                                                  CountVectorizer(decode_error='ignore',\n",
       "                                                                                  max_df=0.7538214490256765,\n",
       "                                                                                  min_df=4,\n",
       "                                                                                  ngram_range=(1,\n",
       "                                                                                               4))),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  'passthrough')])),\n",
       "                                                ('text_len',\n",
       "                                                 Pipeline(steps=[('get_text',\n",
       "                                                                  SelectColumnsTransformer(col...\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints=None,\n",
       "                               learning_rate=0.13027378372211787,\n",
       "                               max_delta_step=None, max_depth=4,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               random_state=None, reg_alpha=None,\n",
       "                               reg_lambda=None, scale_pos_weight=3,\n",
       "                               subsample=None, tree_method='hist',\n",
       "                               validate_parameters=None, verbosity=None))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {'dlf__colsample_bytree': 0.38802577686511047,\n",
    " 'dlf__gamma': 0.20211144034640516,\n",
    " 'dlf__learning_rate': 0.13027378372211787,\n",
    " 'dlf__max_depth': 4.0,\n",
    " 'dlf__min_child_weight': 1.0,\n",
    " 'dlf__scale_pos_weight': 3.0,\n",
    " 'features__text_len': Pipeline(steps=[('get_text', SelectColumnsTransformer(columns='section_text')),\n",
    "                 ('length', LengthExtractor())]),\n",
    " 'features__text_pipeline__vect__lowercase': True,\n",
    " 'features__text_pipeline__vect__max_df': 0.7538214490256765,\n",
    " 'features__text_pipeline__vect__min_df': 4.0,\n",
    " 'features__text_pipeline__vect__ngram_range': (1, 4)}\n",
    "\n",
    "model_params['features__text_pipeline__vect__min_df'] = int(model_params['features__text_pipeline__vect__min_df'])\n",
    "model_params['dlf__max_depth'] = int(model_params['dlf__max_depth'])\n",
    "model_params['dlf__min_child_weight'] = int(model_params['dlf__min_child_weight'])\n",
    "model_params['dlf__scale_pos_weight'] = int(model_params['dlf__scale_pos_weight'])\n",
    "\n",
    "best_model = pipeline\n",
    "best_model.set_params(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87559029",
   "metadata": {},
   "source": [
    "## Test Set Performance\n",
    "\n",
    "With a model selected, we use the 20% test set to measure the performance of the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4dac720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:52:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Overall')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_model.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "# count the number of labels\n",
    "labels = np.unique(y_pred)\n",
    "\n",
    "data = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "# use sns.heatmap on top of confusion_matrix to show the confusion matrix\n",
    "ax = sns.heatmap(df_cm,xticklabels=True, annot=True, fmt='.0f')\n",
    "ax.set(title=\"Overall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f584ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       265\n",
      "           1       0.94      1.00      0.97        92\n",
      "\n",
      "    accuracy                           0.98       357\n",
      "   macro avg       0.97      0.99      0.98       357\n",
      "weighted avg       0.98      0.98      0.98       357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c8fed2",
   "metadata": {},
   "source": [
    "The fit model was 98% accurate on the test set.  This provides an estimate of how accurate our model would be on new data.  With this estimate, we can refit the model using the entire training set below.  This refit model was used to apply classifications to the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d05386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:52:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "refit = best_model.fit(dataframe,dataframe.jim_crow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
